import sqlite3
import string
from string import punctuation
from os import listdir
from collections import Counter
from nltk.corpus import stopwords
from sqlite3 import Error

def load_dataset(dataset_name):
    try:
        #create connection
        conn = sqlite3.connect(dataset_name)
        cur = conn.cursor()
        print('connected')
    except Exception as e:
        print("Encountered some error while making connection with database! ",str(e))
		
def strip_and_convert(data):
    #data=str(data).replace(",","")
    data=str(data).replace('("',"")
    data=str(data).replace("('","")
    data=str(data).replace(")","")
    data=str(data).replace('",','')
    data=str(data).replace("',","")
    #data=str(data).replace("')","")
    #data=str(data).replace('")','')
    return data
	
def clean_reviews(reviews):
    # split into tokens by white space
    tokens = reviews.split()
    # remove punctuation from each token
    table = str.maketrans('', '', punctuation)
    tokens = [w.translate(table) for w in tokens]
    # remove remaining tokens that are not alphabetic
    tokens = [word for word in tokens if word.isalpha()]
    # filter out stop words
    stop_words = set(stopwords.words('english'))
    tokens = [w for w in tokens if not w in stop_words]
    # filter out short tokens
    tokens = [word for word in tokens if len(word) > 1]
    print(tokens)
    return tokens

# save list to file
def save_list_to_file(lines, filename):
    data = '\n'.join(lines)
    file = open(filename, 'w')
    file.write(data)
    file.close()

# load doc, clean and return line of tokens
def clean_record(record, vocab):
    # load the doc
    doc = strip_and_convert(record)
    # clean doc
    tokens = clean_reviews(doc)
    # filter by vocab
    tokens = [w for w in tokens if w in vocab]
    return ' '.join(tokens)
	
def process_reviews(dataset, sentiment, vocab):
    #create connection
    conn = sqlite3.connect(dataset)
    cur = conn.cursor()
    lines = list()
    if(sentiment == "positive"):
        query = "select text from Tweets where airline_sentiment='positive'"
                
    elif(sentiment == "negative"):
        query = "select text from Tweets where airline_sentiment='negative'"
    elif(sentiment == "neutral"):
        query = "select text from Tweets where airline_sentiment='neutral'"
    else:
        query = "select Text from Tweets"
    records_found = cur.execute(query)
    print(records_found)
    count = 0
    for each_record in records_found:
        line = clean_record(each_record, vocab)
        print(line)
        #add this data to the list
        lines.append(line)
        count= count + 1
    print(count)
    return lines
	
def add_review_to_vocab(data, vocab):
    data = strip_and_convert(data)
    tokens = clean_reviews(data)
    vocab.update(tokens)
	
def process_reviews_vocab(dataset, vocab):
    conn = sqlite3.connect(dataset)
    cur = conn.cursor()
    query = "select text from tweets"
    records_found = cur.execute(query)
    for record in records_found:
        add_review_to_vocab(record, vocab)
    conn.close()

def create_vocab(dataset):
    vocab = Counter()
    #add all reviews to the vocab
    process_reviews_vocab(dataset, vocab)
    # check the size of the vocab
    print(len(vocab))
    # print the top words in the vocab
    print(vocab.most_common(50))
    # keep tokens with > 5 occurrence
    min_occurane = 2
    tokens = [k for k,c in vocab.items() if c >= min_occurane]
    print(len(tokens))
    # save tokens to a vocabulary file
    save_list_to_file(tokens, 'vocab.txt')

def check_vocab():
    try:
        file = open('vocab.txt','r')
        print("FILE ALREADY EXIST")
#         text = file.read()
#         print(text)
        file.close()
        return 1;
    except Exception as e:
        # run code to create vocab file
        print("FILE DOES NOT EXIST, CREATING....")
        create_vocab('database.sqlite')

def load_vocab(filename):
    file = open(filename, 'r')
    vocab_text = file.read()
    file.close()
    return vocab_text
	
if __name__ == '__main__':
    #write code to check whether vocab file is created or not
    # if yes then skip this step
    # if no then create vocab file first before moving to the next part
    x=check_vocab()
    if(x == 1):
        vocab_filename = 'vocab.txt'
        vocab = load_vocab(vocab_filename)
        vocab = vocab.split()
        vocab = set(vocab)
        #negative reviews
        negative_reviews = process_reviews('database.sqlite', 'negative', vocab)
        print(negative_reviews)
        save_list_to_file(negative_reviews, 'negative_reviews.txt')
        #positive reviews
        positive_reviews = process_reviews('database.sqlite', 'positive', vocab)
        save_list_to_file(positive_reviews, 'positive_reviews.txt')
        #neutral reviews
        neutral_reviews = process_reviews('database.sqlite', 'neutral', vocab)
        save_list_to_file(neutral_reviews, 'neutral_reviews.txt')
    else:
        print("Please generate vocab file first and then try again")